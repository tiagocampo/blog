---
layout: post
title: Dealing with outliers in machine-learning
tags: sklearn python machine-learning theory
mathjax: false
description: In this blog post we discuss methods to treat outliers
---

* Do not remove this line (it will not be displayed)
{:toc}

---

# Introduction

An outlier is an observation in a given dataset that lies far from the rest of the observations. They can be extreme values that are outside the range of what is expected an unlike the other data in the dataset.

There is no precise way to define and identify outliers in general because of the specifics of each dataset. Instead someone has to interpret the raw observations and decide whether a value is an outlier or not.

In the following we will describe several methods to detect an deal with outliers

# Standard deviation method (Z-score)

If the data follows a Gaussian distribution we can use the standard deviation of the sample as a cut-of for identifying outliers.

The Gaussian distribution has the property that the standard deviation from the mean can be used to reliably summarize the percentage of values in the sample.

- 1 std from mean covers 68% of the data
- 2 std from mean covers 95% of the data
- 3 std from mean covers 99.7% of the data

A value that falls outside of the 3 standard deviations is part of the distribution but is an unlikely or rare event. For smaller samples of data one could use 2 standard 
deviations or for larger samples, 4 standard deviations.

```python
# calculate summary statistics
data_mean, data_std = mean(data), std(data)
# identify outliers
cut_off = data_std * 3
lower, upper = data_mean - cut_off, data_mean + cut_off
# identify outliers
outliers = [x for x in data if x < lower or x > upper]
```

<br/>
<div class="card center-image" style="max-width: 40rem;">
  <img src="{{site.baseurl}}/assets/images/fig1_OLD.png" class="card-img-top" alt="...">
  <div class="card-body">
    <p class="card-text">Detecting Outliers with Z-scores. Image source: https://laptrinhx.com/ taken from https://www.analyticsvidhya.com/blog/2021/05/detecting-and-treating-outliers-treating-the-odd-one-out/</p>
  </div>
</div>
<br/>

# IQR - inter quartile range

Not all data is normal or normal enough to treat it as being drawn from a Gaussian distribution. A good statistic for summarizing a non-Gaussian distribution sample of data is the inter quartile range (IQR).

The IQR method is used by the box plot to highlight outliers and it is the difference between Q3 (75th percentile) and Q1 (25th percentile). The IQR method computed lower and upper bounds to identify outliers.

- lower bound: Q1 - 1.5*(Q3-Q1)
- upper bound: Q3 + 1.5*(Q3-Q1)

Any value below the lower bound and above the upper bound are considered to be outliers.

```python
outliers = []
def detect_outliers_iqr(data):
    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    # print(q1, q3)
    IQR = q3-q1
    lwr_bound = q1-(1.5*IQR)
    upr_bound = q3+(1.5*IQR)
    # print(lwr_bound, upr_bound)
    for i in data: 
        if (i<lwr_bound or i>upr_bound):
            outliers.append(i)
    return outliers# Driver code
sample_outliers = detect_outliers_iqr(sample)
print("Outliers from IQR method: ", sample_outliers)
```
<br/>
<div class="card center-image" style="max-width: 40rem;">
  <img src="{{site.baseurl}}/assets/images/fig2_OLD.png" class="card-img-top" alt="...">
  <div class="card-body">
    <p class="card-text">IQR to detect outliers. Image source: https://www.analyticsvidhya.com/blog/2021/05/detecting-and-treating-outliers-treating-the-odd-one-out/</p>
  </div>
</div>
<br/>

# Automatic Outlier Detection

In the sklearn there is a method to automatic detect outliers using one-class classification.

The anomaly score of each sample is called the Local Outlier Factor. It measures the local deviation of the density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers.

```python
from sklearn.neighbors import LocalOutlierFactor
...
# identify outliers in the training dataset
lof = LocalOutlierFactor()
yhat = lof.fit_predict(X_train)
# select all rows that are not outliers
mask = yhat != -1
X_train, y_train = X_train[mask, :], y_train[mask]
...
```

There are also other methods in sklearn, such as 

```python
from sklearn.svm import OneClassSVM
from sklearn.covariance import EllipticEnvelope
from sklearn.ensemble import IsolationForest
```

# Handling outliers

Once outliers are detected we can trim/remove then, we could impute use quantile or mean/median. Each technique should be tested to each specific dataset.


# References

- [How to Remove Outliers for Machine Learning](https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/){:target="_blank"}
- [Detecting and Treating Outliers: Treating the odd one out!](https://www.analyticsvidhya.com/blog/2021/05/detecting-and-treating-outliers-treating-the-odd-one-out/){:target="_blank"}
- [Outlier detection methods in Machine Learning](https://towardsdatascience.com/outlier-detection-methods-in-machine-learning-1c8b7cca6cb8){:target="_blank"}
- [LocalOutlierFactor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor){:target="_blank"}
- [4 Automatic Outlier Detection Algorithms in Python](https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/){:target="_blank"}